{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a importar las librerías necesarias para la tarea, ya se explicará más adelante el uso de _combinations_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybalu.feature_extraction import lbp_features\n",
    "from pybalu.feature_selection import clean, sfs\n",
    "from pybalu.feature_transformation import normalize\n",
    "from pybalu.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = [i for i in listdir('faces_ARLQ') if i.endswith('png')]\n",
    "usable_faces = [i for i in faces if int(i[9:11]) < 8]\n",
    "odd_faces_names = [i for i in usable_faces if int(i[5:8]) % 2]\n",
    "even_faces_names = [i for i in usable_faces if not int(i[5:8]) % 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras cargar todos los nombres de las imágenes en la carpeta _faces_ARLQ_ se procede a dividirlas entre pares e impares, y las labels se trasladan para que las pares no vayan de 1 a 100 con salto de 2, sino que de 0 a 49, correlativamente, lo anterior debido a una limitación de la implementación de SFS en pybalu que lo exigía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_names = [i for i in odd_faces_names if int(i[9:11]) > 1]\n",
    "testing_names = [i for i in odd_faces_names if int(i[9:11]) <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [imread(f'faces_ARLQ/{i}') for i in training_names]\n",
    "y_training = np.array([int(i[5:8]) // 2 for i in training_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = [imread(f'faces_ARLQ/{i}') for i in testing_names]\n",
    "y_testing = np.array([int(i[5:8]) // 2 for i in testing_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se probaron distintas combinaciones de _hdiv_ y _vdiv_, ambos entre los valores de 1 y 7. En un principio se probó con las más grandes (7x7) pero eran excesivamente lentas de procesar en el SFS, y se optó por probar las combinaciones extremas y más acotadas, esto es 5x1 y 1x5 iterando hasta 1x1. Si bien en varios experimentos se obtuvo un buen rendimiento (100% o muy cercano), el que mejor pondera tiempo de ejecución y rendimiento es el siguiente: 4x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiv = 4\n",
    "vdiv = 2\n",
    "training_features = np.array([lbp_features(i, hdiv=hdiv, vdiv=vdiv, mapping='nri_uniform') for i in training])\n",
    "testing_features = np.array([lbp_features(i, hdiv=hdiv, vdiv=vdiv, mapping='nri_uniform') for i in testing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza el método de _mapping_ \"nri_uniform\" dado que si bien no se necesita ser invariante a la rotación porque todas las fotos están orientadas igual, si hay variaciones de brillo en las escalas de gris, y este mapping toma eso en consideración. Además acelera considerablemente los tiempos de ejecución, puesto que son menos features para lograr lo invariante al brillo en la escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 472), (300, 472))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_features_indexes = clean(training_features)\n",
    "cleaned_features = training_features[:, cleaned_features_indexes]\n",
    "cleaned_testing_features = testing_features[:, cleaned_features_indexes] # mismo clean para testing\n",
    "training_features.shape, cleaned_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features, norm_a, norm_b = normalize(cleaned_features)\n",
    "normalized_testing_features = cleaned_testing_features * norm_a + norm_b # misma normalización para testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 30.0/30.0 [01:26<00:00, 2.89s/ features]\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = 30\n",
    "selected_features_indexes = sfs(normalized_features, y_training, n_features=N_FEATURES, method=\"fisher\", show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar las features seleccionadas inmediatamente tras el SFS con 30 features entrega peores resultados que con menos features, de hecho el resultado que mostraré a continuación utiliza solo 28 features, sin embargo, esas 28 características no se obtienen de un SFS de N=28 por lo que empíricamente lo que se probó fue con combinaciones que dieran el mayor rendimiento.\n",
    "\n",
    "Se computaron algunas combinaciones de las features seleccionadas por el SFS tales que maximizaran el resultado, considerando de ante mano que en muchas pruebas se alcanzaba el 100%. Para esto se utilizaron combinaciones de largo i-2 e i-1 para i tamaño del SFS realizado, por lo que el índice con el que se finaliza es el 30, para una combinación de largo 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = []\n",
    "indexes = list(combinations(selected_features_indexes, 28)) + list(combinations(selected_features_indexes, 29))\n",
    "for ixs in indexes:\n",
    "    sf = normalized_features[:, ixs]\n",
    "    n = KNeighborsClassifier(n_neighbors=1)\n",
    "    n.fit(sf, y_training)\n",
    "    ctf = testing_features[:, cleaned_features_indexes]\n",
    "    ntf = ctf * norm_a + norm_b\n",
    "    stf = ntf[:, ixs]\n",
    "    yp = n.predict(stf)\n",
    "    corr = (yp == y_testing).astype(int).sum()\n",
    "    acc = corr / y_testing.size * 100\n",
    "    s.append([acc, ixs])\n",
    "best_selected_indexes = max(s)[1]\n",
    "max(s)[0], len(max(s)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa se consiguió un 100%, y esto se da con 28 características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444, 404, 385, 384, 266, 290, 146, 264, 383, 295, 85, 380, 54, 230, 148, 140, 116, 176, 38, 91, 274, 27, 77, 172, 420, 374, 332, 224)\n"
     ]
    }
   ],
   "source": [
    "print(best_selected_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de no querer correr el código anterior, considerando el tiempo de demora del SFS de 30 features, se puede descomentar la siguiente linea, que es el resultado de lo obtenido anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_selected_indexes = (444, 404, 385, 384, 266, 290, 146, 264, 383, 295, 85, 380, 54, 230, 148, 140, 116, 176, 38, 91, 274, 27, 77, 172, 420, 374, 332, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar el rendimiento (es lo mismo que se hace en cada iteración del _for_ interior del código anterior) se indexa la matriz de imagenes limpiada y normalizada con esos índices seleccionados, tanto para training como para testing, se entrena el clasificador de KNN y finalmente se evalúa el rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = normalized_features[:, best_selected_indexes]\n",
    "selected_testing_features = normalized_testing_features[:, best_selected_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = KNeighborsClassifier(n_neighbors=1)\n",
    "neighbors.fit(selected_features, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = neighbors.predict(selected_testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = (y_prediction == y_testing).astype(int).sum()\n",
    "accuracy = correct / y_testing.size * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte, el procedimiento es muy similar a lo anterior, cargando las pares en vez de las impares, pero utilizando _best_selected_indexes_ que fue obtenido en el experimento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_training_names = [i for i in even_faces_names if int(i[9:11]) > 1]\n",
    "even_testing_names = [i for i in even_faces_names if int(i[9:11]) <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_training = [imread(f'faces_ARLQ/{i}') for i in even_training_names]\n",
    "even_y_training = np.array([int(i[5:8]) // 2 for i in even_training_names])\n",
    "even_testing = [imread(f'faces_ARLQ/{i}') for i in even_testing_names]\n",
    "even_y_testing = np.array([int(i[5:8]) // 2 for i in even_testing_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_training_features = np.array([lbp_features(i, hdiv=hdiv, vdiv=vdiv, mapping='nri_uniform') for i in even_training])\n",
    "even_testing_features = np.array([lbp_features(i, hdiv=hdiv, vdiv=vdiv, mapping='nri_uniform') for i in even_testing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_cleaned_training_features = even_training_features[:, cleaned_features_indexes]\n",
    "even_cleaned_testing_features = even_testing_features[:, cleaned_features_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_normalized_training_features, even_norm_a, even_norm_b = normalize(even_cleaned_training_features)\n",
    "even_normalized_testing_features = even_cleaned_testing_features * even_norm_a + even_norm_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_selected_training_features = even_normalized_training_features[:, best_selected_indexes]\n",
    "even_selected_testing_features = even_normalized_testing_features[:, best_selected_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(even_selected_training_features, even_y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_y_prediction = knn.predict(even_selected_testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_correct = (even_y_prediction == even_y_testing).astype(int).sum()\n",
    "even_accuracy = even_correct / even_y_testing.size * 100\n",
    "even_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarmente, como se observa, el rendimiento es casi perfecto con esos índices, y se obtiene un 100% y un 98% en cada experimento respectivamente, utilizando las features seleccionadas a partir de la parte impar del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
