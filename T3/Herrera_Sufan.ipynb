{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from pybalu.feature_selection import clean, sfs\n",
    "from pybalu.feature_transformation import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Común"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes funciones se definen para poder dividir el set de datos en los sets de entrenamiento y testing de acuerdo a lo pedido, esto es, que se utilice el primer 80% de las muestras de cada clase para entrenar y el 20% restante para las pruebas.\n",
    "\n",
    "Con ese objetivo se crea el método `train_test_split` para ser consistente con el método ampliamente conocido de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(array, proportion):\n",
    "    splitting_point = round(array.shape[0] * (1 - proportion))\n",
    "    return array[:splitting_point], array[splitting_point:]\n",
    "\n",
    "def train_test_split(features, labels, proportion):\n",
    "    classes = np.unique(labels)\n",
    "    features_train = []\n",
    "    features_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    for cl in classes:\n",
    "        class_train, class_test = split(features[(labels == cl)[:, 0]], proportion)\n",
    "        class_train_labels, class_test_labels = split(labels[labels == cl], proportion)\n",
    "        features_train.append(class_train)\n",
    "        features_test.append(class_test)\n",
    "        labels_train.append(class_train_labels)\n",
    "        labels_test.append(class_test_labels)\n",
    "    f_train = features_train[0]\n",
    "    f_test = features_test[0]\n",
    "    l_train = labels_train[0]\n",
    "    l_test = labels_test[0]\n",
    "    for x in range(1, classes.size):\n",
    "        f_train = np.vstack((f_train, features_train[x]))\n",
    "        f_test = np.vstack((f_test, features_test[x]))\n",
    "        l_train = np.hstack((l_train, labels_train[x]))\n",
    "        l_test = np.hstack((l_test, labels_test[x]))\n",
    "    return f_train, f_test, l_train.reshape(l_train.size, 1), l_test.reshape(l_test.size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tortillas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta sección cabe recordar que se pide explícitamente eliminar las características de posición por lo sesgado del _dataset_, de modo que se eliminan de antemano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('set04-tortillas.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = ['center of grav i      ',\n",
    "            'center of grav j      ',\n",
    "            'Ellipse-centre i      ',\n",
    "            'Ellipse-centre j      ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for feature in excluded:\n",
    "    indexes.append(np.where(data['fn'] == feature)[0][0])\n",
    "    \n",
    "position_indexes = np.array(indexes)\n",
    "non_position_indexes = np.setdiff1d(np.array(range(data['fn'].size)), position_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['f'][:, non_position_indexes]\n",
    "y = data['d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dividen los datos en la proporción pedida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace `clean` de los datos, cuidando de aplicar los índices obtenidos también al set de testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_indexes = clean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = X_train[:, clean_indexes]\n",
    "X_test_cleaned = X_test[:, clean_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza normalización, también aplicandola al set de testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized, a, b = normalize(X_train_cleaned)\n",
    "X_test_normalized = X_test_cleaned * a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una selección de características con `SFS`, se probó con diferentes cantidades de características, pero ya con 10 se obtenían resultados perfectos. También se aplican los índices obtenidos al set de pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 10.0/10.0 [00:01<00:00, 6.81 features/s]\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = 10\n",
    "selected_indexes = sfs(X_train_normalized, y_train, n_features=N_FEATURES, method=\"fisher\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train_normalized[:, selected_indexes]\n",
    "X_test_selected = X_test_normalized[:, selected_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalmente determinar la precisión del método aplicado se prueba directamente con un `KNN` de un vecino, y el resultado es de un 100%. Sin embargo, también se probó añadiendo `PCA` y luego clasificando con `KNN` o directamente con `LDA`, sin embargo como ya se obtenía un 100% sin realizar lo anterior se dejó este método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "knn_sfs = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_sfs.fit(X_train_selected, y_train)\n",
    "print(f'{knn_sfs.score(X_test_selected, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza en primer lugar el comando `%reset -f array` para que todos los arreglos de numpy se _reseteen_ de modo de evitar por cualquier razón utilizar datos de la sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se verá en los experimentos, esta vez si mejora el rendimiento al utilizar `PCA`, `LDA` o `QDA`, por lo que se incluyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procedimiento es muy similar a lo anterior por lo que no se comentará nuevamente hasta las partes donde difiera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('set05-face-detection.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['f']\n",
    "y = data['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_indexes = clean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = X_train[:, clean_indexes]\n",
    "X_test_cleaned = X_test[:, clean_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized, a, b = normalize(X_train_cleaned)\n",
    "X_test_normalized = X_test_cleaned * a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 9.00/9.00 [00:00<00:00, 9.15 features/s]\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = 9\n",
    "selected_indexes = sfs(X_train_normalized, y_train, n_features=N_FEATURES, method=\"fisher\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train_normalized[:, selected_indexes]\n",
    "X_test_selected = X_test_normalized[:, selected_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar la selección con `SFS` con 9 características (luego de haber intentado con diversos números), se obtienen resultados muy satisfactorios, sin embargo, no perfectos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.5781990521327%\n",
      "90.56603773584906%\n"
     ]
    }
   ],
   "source": [
    "knn_sfs = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_sfs.fit(X_train_selected, y_train)\n",
    "print(f'{knn_sfs.score(X_train_selected, y_train) * 100}%')\n",
    "print(f'{knn_sfs.score(X_test_selected, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante notar que no tiene sentido hacer PCA de 9 componentes a algo que de por si tiene 9 dimensiones ya que no se juntaría la información de ningún par de ellas en otro eje nuevo.\n",
    "\n",
    "Por otro lado, se prueba que con menos no hay mejoras significativas del rendimiento, lo que hace sentido, porque de lo contrario, significaría que el método sigue estando sobreajustado a los datos, pero con 9 características desde las más de mil iniciales, es poco probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=6)\n",
    "X_train_pcaed = pca.fit_transform(X_train_selected)\n",
    "X_test_pcaed = pca.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.10426540284361%\n",
      "88.67924528301887%\n"
     ]
    }
   ],
   "source": [
    "knn_pca = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_pca.fit(X_train_pcaed, y_train)\n",
    "knn_pca.score(X_test_pcaed, y_test)\n",
    "print(f'{knn_pca.score(X_train_pcaed, y_train) * 100}%')\n",
    "print(f'{knn_pca.score(X_test_pcaed, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se aprecia, con `PCA` de 2 vecinos no se mejora en training, por lo que no es natural elegir este método por sobre el otro. Ahora, se muestran las pruebas con `LDA` o `QDA` en vez de `KNN` directo tras la selección o después de la aplicación de `PCA`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.6303317535545%\n",
      "92.45283018867924%\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(solver='svd', n_components=10)\n",
    "lda.fit(X_train_selected, y_train)\n",
    "print(f'{lda.score(X_train_selected, y_train) * 100}%')\n",
    "print(f'{lda.score(X_test_selected, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.89099526066352%\n",
      "90.56603773584906%\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(solver='lsqr', shrinkage='auto', n_components=10)\n",
    "lda.fit(X_train_pcaed, y_train)\n",
    "print(f'{lda.score(X_train_pcaed, y_train) * 100}%')\n",
    "print(f'{lda.score(X_test_pcaed, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa el rendimiento en entrenamiento no mejora con `LDA`, por lo que no es natural elegir esto, y si se eligiera por el desempeño en testing se estaría haciendo algo que no tiene sentido (porque no siempre se tiene acceso a esos datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo resta probar con el otro analisis de discriminante, `QDA`, en vez del lineal. Nuevamente sobre los datos tras la selección de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.10426540284361%\n",
      "98.11320754716981%\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "qda.fit(X_train_selected, y_train)\n",
    "print(f'{qda.score(X_train_selected, y_train) * 100}%')\n",
    "print(f'{qda.score(X_test_selected, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.8388625592417%\n",
      "94.33962264150944%\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "qda.fit(X_train_pcaed, y_train)\n",
    "print(f'{qda.score(X_train_pcaed, y_train) * 100}%')\n",
    "print(f'{qda.score(X_test_pcaed, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en los 3 casos con clasificadores distintos a `KNN` no se obtuvo mejores resultados en training lo natural es decantarse por la primera opción, previa a PCA. Sin embargo, se puede argumentar que las últimas son más robustas en base a que pueden utilizar menos componentes, pero nunca argumentarlo en base a los resultados de testing, puesto que es ilegal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, para clasificar ahora si se puede usar KNN con 1 vecino, ya que antes se usaba con 2 para evitar tener 100% siempre con datos de training ya que eso no permitía comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.33962264150944%\n"
     ]
    }
   ],
   "source": [
    "knn_sfs = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_sfs.fit(X_train_selected, y_train)\n",
    "print(f'{knn_sfs.score(X_test_selected, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo hecho la elección con los _scores_ de training, se ve que se llega a un resultado bastante bueno en testing, inferior al de QDA pero eso sería con información que no se tiene a priori e ilegal, por lo que el resultado final es de **94.3%**, tras SFS con KNN de 1 vecino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Géneros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta sección nuevamente se tiene cuidado de no utilizar los mismos arreglos, y se procede de manera similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('set06-gender.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['f']\n",
    "y = data['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_indexes = clean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = X_train[:, clean_indexes]\n",
    "X_test_cleaned = X_test[:, clean_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized, a, b = normalize(X_train_cleaned)\n",
    "X_test_normalized = X_test_cleaned * a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 12.0/12.0 [00:01<00:00, 9.56 features/s]\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = 12\n",
    "selected_indexes = sfs(X_train_normalized, y_train, n_features=N_FEATURES, method=\"fisher\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([233,  59, 265, 263, 301,  51, 106, 131,   6, 164, 112,  28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_selected = X_train_normalized[:, selected_indexes]\n",
    "X_test_selected = X_test_normalized[:, selected_indexes]\n",
    "selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.97540983606558%\n",
      "62.295081967213115%\n"
     ]
    }
   ],
   "source": [
    "knn_sfs = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_sfs.fit(X_train_selected, y_train)\n",
    "print(f'{knn_sfs.score(X_train_selected, y_train) * 100}%')\n",
    "print(f'{knn_sfs.score(X_test_selected, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es bastante bueno en training, pero con PCA en training se puede mejorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "X_train_pcaed = pca.fit_transform(X_train_selected)\n",
    "X_test_pcaed = pca.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.38524590163934%\n",
      "62.295081967213115%\n"
     ]
    }
   ],
   "source": [
    "knn_pca = KNeighborsClassifier(n_neighbors=2) # uso 2 porque sino sería 100% en training\n",
    "knn_pca.fit(X_train_pcaed, y_train)\n",
    "print(f'{knn_pca.score(X_train_pcaed, y_train) * 100}%')\n",
    "print(f'{knn_pca.score(X_test_pcaed, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, similar a lo realizado en la tarea anterior, por como se comporta `SFS` una opción es probar con combinaciones de largo inferior, es decir subconjuntos de índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9979508196721312, 12, (265, 301, 51, 106, 131, 112, 28)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = []\n",
    "for i in range(6, N_FEATURES + 1):\n",
    "    indexes = combinations(selected_indexes[:i], i - 5)\n",
    "    for x in indexes:\n",
    "        xtrs = X_train_normalized[:, x]\n",
    "        xtts = X_test_normalized[:, x]\n",
    "        k = KNeighborsClassifier(n_neighbors=2) # con 2 porque sino siempre es 100% con training\n",
    "        k.fit(xtrs, y_train)\n",
    "        r.append([k.score(xtrs, y_train), i, x]) # xtrs es training.\n",
    "best_selected_indexes = max(r)[2]\n",
    "max(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer la elección es necesario utilizar el set de training porque elegir los parámetros usando el set de testing es _ilegal_. Las comparciones a posterior se realizan con los scores de testing pero la elección de parámetros no. Y es así para todo el código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no se desea ejecutar el código para no computar las combinaciones, comentarlo y descomentar la línea del siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 301, 51, 106, 131, 112, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_selected_indexes\n",
    "# best_selected_indexes = np.array([265, 301, 51, 106, 131, 112, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizamos el procedimiento de `KNN` con lo obtenido, y se verá si vale la pena aplicar `PCA` o utilizar otro método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train_normalized[:, best_selected_indexes]\n",
    "X_test_selected = X_test_normalized[:, best_selected_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.79508196721312%\n",
      "79.50819672131148%\n"
     ]
    }
   ],
   "source": [
    "knn_sfs = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_sfs.fit(X_train_selected, y_train)\n",
    "print(f'{knn_sfs.score(X_train_selected, y_train) * 100}%')\n",
    "print(f'{knn_sfs.score(X_test_selected, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, en training se mejora un poco respecto al resultado anterior, esto es de 99.4 a 99.8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con `PCA`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.79508196721312%\n",
      "81.14754098360656%\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=6)\n",
    "X_train_pcaed = pca.fit_transform(X_train_selected)\n",
    "X_test_pcaed = pca.transform(X_test_selected)\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_pca.fit(X_train_pcaed, y_train)\n",
    "print(f'{knn_pca.score(X_train_pcaed, y_train) * 100}%')\n",
    "print(f'{knn_pca.score(X_test_pcaed, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, el rendimiento no mejora para cualquier valor de `N` (componentes), en training, pero si se mantiene practicamente igual reduciendo la cantidad de componentes, lo que es positivo considerando la robustez.\n",
    "\n",
    "Sin embargo, se observa que en testing es mejor, pero no habría manera de discriminar entre esto y lo anterior (sin PCA) porque los rendimientos son iguales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, por otro lado, cabe señalar que si bien para elegir un mejor clasificador es buena idea utilizar k>1 en los vecinos cercanos porque sino se iguala a si mismo, es buena idea para testing utilizar el vecino más cercano, por lo que se ilustrará el rendimiento final de los casificadores con k=1, ya que con un set de datos diferente al que se usó para entrenar **sí tiene sentido** hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.0655737704918%\n",
      "88.52459016393442%\n"
     ]
    }
   ],
   "source": [
    "# SIN PCA\n",
    "knn_sfs = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_sfs.fit(X_train_selected, y_train)\n",
    "print(f'{knn_sfs.score(X_test_selected, y_test) * 100}%')\n",
    "# CON PCA\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_pca.fit(X_train_pcaed, y_train)\n",
    "print(f'{knn_pca.score(X_test_pcaed, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en ambos se obtuvo el mismo resultado en training, es imposible saber sin acceso a los datos de testing cual habría desempeñado mejor, por lo que se opta por considerar el **86.06%** como el mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
